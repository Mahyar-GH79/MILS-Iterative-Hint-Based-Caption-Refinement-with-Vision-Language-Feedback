# MILS\+: Iterative Hint Based Caption Refinement with Vision Language Feedback

This repository contains the code for the report *MILS+: Iterative Hint Based Caption Refinement with Vision Language Feedback*.  
The report was prepared for course **CMSC848K** at the **Department of Computer Science, University of Maryland, College Park**.

## Overview

MILS+ is an iterative image caption refinement framework. Given an initial caption for an image, the system repeatedly improves the caption by using feedback (semantic hints) generated by a vision language model. Each refinement step incorporates this feedback to produce captions that are progressively more accurate, detailed, and faithful to the image content.

This repository provides a complete pipeline for:
- generating initial captions
- iteratively refining captions using hint based vision language feedback
- evaluating captions on the COCO evaluation dataset
- visualizing qualitative improvements

---

## Dataset Setup (Required)

This project uses the **COCO 2017 validation dataset**.

### Step 1: Download COCO images

Download **val2017 images** from the official COCO website:
https://cocodataset.org/#download

File:
